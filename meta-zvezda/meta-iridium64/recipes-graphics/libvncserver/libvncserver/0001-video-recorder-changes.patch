diff -r -u --new-file a/client_examples/vnc2mpg.c b/client_examples/vnc2mpg.c
--- a/client_examples/vnc2mpg.c	2022-10-19 16:40:54.503955885 +0300
+++ b/client_examples/vnc2mpg.c	2022-10-21 00:19:16.749252355 +0300
@@ -1,3 +1,4 @@
+#if 1
 /**
  * @example vnc2mpg.c
  * Simple movie writer for vnc; based on Libavformat API example from FFMPEG
@@ -27,14 +28,34 @@
 #include <stdio.h>
 #include <string.h>
 #include <math.h>
+#include <time.h>
 #include <signal.h>
 #include <sys/time.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <sys/statvfs.h>
+#include <libavcodec/avcodec.h>
 #include <libavformat/avformat.h>
 #include <libswscale/swscale.h>
 #include <rfb/rfbclient.h>
 
+#if 0
 #define VNC_PIX_FMT       AV_PIX_FMT_RGB565  /* pixel format generated by VNC client */
+//#define VNC_PIX_FMT       AV_PIX_FMT_RGB32  /* pixel format generated by VNC client */
+//#define VNC_PIX_FMT       AV_PIX_FMT_YUV420P  /* pixel format generated by VNC client */
 #define OUTPUT_PIX_FMT    AV_PIX_FMT_YUV420P /* default pix_fmt */
+#else
+#define VNC_PIX_FMT       AV_PIX_FMT_RGB32  /* pixel format generated by VNC client */
+#define OUTPUT_PIX_FMT    AV_PIX_FMT_YUVJ420P /* default pix_fmt */
+#endif
+
+#define VIDEO_DIR_TMP "/tmp/"
+#define VIDEO_DIR_RES "/tmp/video/"
+
+#define USE_SEP_AVFRAMES
+
+//#define MIN_SPACE_SIZE (200*1024*1024)
+#define MIN_SPACE_SIZE (128*1024*1024)
 
 static int write_packet(AVFormatContext *oc, const AVRational *time_base, AVStream *st, AVPacket *pkt)
 {
@@ -59,12 +80,19 @@
     struct SwsContext *sws;
 } VideoOutputStream;
 
+#ifdef USE_SEP_AVFRAMES
+AVFrame *frame = NULL;
+AVFrame *tmp_frame = NULL;
+#endif
+
 /* Add an output video stream. */
 int add_video_stream(VideoOutputStream *ost, AVFormatContext *oc,
                        enum AVCodecID codec_id, int64_t br, int sr, int w, int h)
 {
     int i;
 
+codec_id = AV_CODEC_ID_MJPEG;
+printf( "codec_id=%d(%x)\n", codec_id, codec_id );
     /* find the encoder */
     ost->codec = avcodec_find_encoder(codec_id);
     if (!(ost->codec)) {
@@ -144,6 +172,7 @@
 
 int open_video(AVFormatContext *oc, VideoOutputStream *ost)
 {
+//printf( "open_video 1\n" ); fflush( stdout );
     int ret;
     /* open the codec */
     ret = avcodec_open2(ost->enc, ost->codec, NULL);
@@ -158,7 +187,14 @@
         return ret;
     } // memory from this call is freed when oc (parent of ost->st) is freed, no need to do it on error in this call
     /* allocate and init a re-usable frame */
+#ifdef USE_SEP_AVFRAMES
+    if( !frame )
+        frame = alloc_picture(ost->enc->pix_fmt, ost->enc->width, ost->enc->height);
+    ost->frame = frame;
+//printf( "open_video 2 %p\n", ost->frame ); fflush( stdout );
+#else
     ost->frame = alloc_picture(ost->enc->pix_fmt, ost->enc->width, ost->enc->height);
+#endif
     if (!(ost->frame)) {
         fprintf(stderr, "Could not allocate video frame\n");
         return -1;
@@ -168,18 +204,29 @@
      * output format. */
     ost->tmp_frame = NULL;
     ost->sws = NULL;
+printf( "FORMAT srv=%d my=%d\n", ost->enc->pix_fmt, VNC_PIX_FMT );
     if (ost->enc->pix_fmt != VNC_PIX_FMT) {
+#ifdef USE_SEP_AVFRAMES
+        if( !tmp_frame )
+            tmp_frame = alloc_picture(VNC_PIX_FMT, ost->enc->width, ost->enc->height);
+        ost->tmp_frame = tmp_frame;
+#else
         ost->tmp_frame = alloc_picture(VNC_PIX_FMT, ost->enc->width, ost->enc->height);
+#endif
         if (!(ost->tmp_frame)) {
             fprintf(stderr, "Could not allocate temporary picture\n");
+#ifndef USE_SEP_AVFRAMES
             av_frame_free(&(ost->frame));
+#endif
             return -2;
         } // from now on need to call av_frame_free(&(ost->tmp_frame)) on error
         ost->sws = sws_getCachedContext(ost->sws, ost->enc->width, ost->enc->height, VNC_PIX_FMT, ost->enc->width, ost->enc->height, ost->enc->pix_fmt, 0, NULL, NULL, NULL);
         if (!(ost->sws)) {
             fprintf(stderr, "Could not get sws context\n");
+#ifndef USE_SEP_AVFRAMES
             av_frame_free(&(ost->frame));
             av_frame_free(&(ost->tmp_frame));
+#endif
             return -3;
         } // from now on need to call sws_freeContext(ost->sws); ost->sws = NULL; on error
     }
@@ -193,6 +240,7 @@
  */
 int write_video_frame(AVFormatContext *oc, VideoOutputStream *ost, int64_t pts)
 {
+//printf( "5_1\n" ); fflush( stdout );
     int ret, ret2;
     AVPacket pkt = { 0 };
     if (pts <= ost->pts) return 0; // nothing to do
@@ -202,6 +250,7 @@
                     ost->tmp_frame->linesize, 0, ost->enc->height, ost->frame->data, ost->frame->linesize);
     }
 
+//printf( "5_2 %p\n", ost->frame ); fflush( stdout );
     /* send the imager to encoder */
     ost->pts = pts;
     ost->frame->pts = ost->pts;
@@ -210,6 +259,7 @@
         fprintf(stderr, "Error sending video frame to encoder: %s\n", av_err2str(ret));
         return ret;
     }
+//printf( "5_3\n" ); fflush( stdout );
     /* read all available packets */
     ret2 = 0;
     for (ret = avcodec_receive_packet(ost->enc, &pkt); ret == 0; ret = avcodec_receive_packet(ost->enc, &pkt)) {
@@ -219,6 +269,7 @@
             /* continue on this error to not gum up encoder */
         }
     }
+//printf( "5_4 %d %d %d\n", ret2, !(ret == AVERROR(EAGAIN)), ret ); fflush( stdout );
     if (ret2 < 0) return ret2;
     if (!(ret == AVERROR(EAGAIN))) return ret; // if AVERROR(EAGAIN), means all available packets output, need more frames (i.e. success)
     return 0;
@@ -255,8 +306,10 @@
 void close_video_stream(VideoOutputStream *ost)
 {
     avcodec_free_context(&(ost->enc));
+#ifndef USE_SEP_AVFRAMES
     av_frame_free(&(ost->frame));
     av_frame_free(&(ost->tmp_frame));
+#endif
     sws_freeContext(ost->sws); ost->sws = NULL;
     ost->codec = NULL; /* codec not an allocated item */
     ost->st = NULL; /* freeing parent oc will free this memory */
@@ -268,11 +321,12 @@
     int ret;
     AVFormatContext *oc;
 
+//printf( "movie_open 1\n" ); fflush( stdout );
     /* allocate the output media context. */
-    ret = avformat_alloc_output_context2(&oc, NULL, NULL, filename);
+    ret = avformat_alloc_output_context2(&oc, NULL, "avi", filename);
     if (ret < 0) {
-        fprintf(stderr, "Warning: Could not deduce output format from file extension: using MP4.\n");
-        ret = avformat_alloc_output_context2(&oc, NULL, "mp4", filename);
+        fprintf(stderr, "Warning: Could not deduce output format from file extension: using AVI.\n");
+        ret = avformat_alloc_output_context2(&oc, NULL, "avi", filename);
     }
     if (ret < 0) {
         fprintf(stderr, "Error: Could not allocate media context: %s.\n", av_err2str(ret));
@@ -280,6 +334,7 @@
     } // from now on, need to call avformat_free_context(oc); oc=NULL; to free memory on error
 
     /* Add the video stream using the default format codec and initialize the codec. */
+//    oc->oformat->video_codec = AV_CODEC_ID_MJPEG;
     if (oc->oformat->video_codec != AV_CODEC_ID_NONE) {
         ret = add_video_stream(video_st, oc, oc->oformat->video_codec, br, fr, w, h);
     } else {
@@ -292,6 +347,7 @@
     } // from now on, need to call close_video_stream(video_st) to free memory on error
 
     /* Now that all the parameters are set, we can open the codecs and allocate the necessary encode buffers. */
+//printf( "movie_open 2\n" ); fflush( stdout );
     ret = open_video(oc, video_st); 
     if (ret < 0) {
         fprintf(stderr, "Error: error opening video codec, error %i\n", ret);
@@ -326,6 +382,7 @@
     return oc;
 }
 
+char full_fname[ 256] = { 0 };
 void movie_close(AVFormatContext **ocp, VideoOutputStream *video_st) {
     AVFormatContext *oc = *ocp;
     /* Write the trailer, if any. The trailer must be written before you
@@ -359,7 +416,7 @@
 char *filename = NULL;
 AVFormatContext *oc = NULL;
 int bitrate = 1000000;
-int framerate = 5;
+int framerate = 10;
 long max_time = 0;
 struct timespec start_time, cur_time;
 
@@ -380,9 +437,18 @@
     return rv;
 }
 
+void check_and_rename()
+{
+    rename( filename, full_fname );
+}
+
 /* VNC callback functions */
 rfbBool vnc_malloc_fb(rfbClient* client) {
+//printf( "vnc_malloc_fb 1\n" ); fflush( stdout );
         movie_close(&oc, &video_st);
+        if( full_fname[ 0] != 0 )
+            check_and_rename();
+printf( "STREAM INFO %d %d %d %d\n", bitrate, framerate, client->width, client->height );
         oc = movie_open(filename, &video_st, bitrate, framerate, client->width, client->height);
 	if (!oc) 
 	    return FALSE;
@@ -402,17 +468,57 @@
 void vnc_update(rfbClient* client,int x,int y,int w,int h) {
 }
 
-/**************************************************************/
-/* media file output */
-int main(int argc, char **argv)
+int init_client(int argc, char *argv[])
 {
-    int i,j;
-
     /* Initialize vnc client structure (don't connect yet). */
+#if 0
     client = rfbGetClient(5,3,2);
     client->format.redShift=11; client->format.redMax=31;
     client->format.greenShift=5; client->format.greenMax=63;
     client->format.blueShift=0; client->format.blueMax=31;
+#else
+//rfbClient* rfbGetClient(int bitsPerSample,int samplesPerPixel,int bytesPerPixel);
+    client = rfbGetClient(8,3,4);
+//    client->format.bigEndian = TRUE;
+    client->format.redShift=16; client->format.redMax=255;
+    client->format.greenShift=8; client->format.greenMax=255;
+    client->format.blueShift=0; client->format.blueMax=255;
+#endif
+
+    /* open VNC connection. */
+    client->MallocFrameBuffer=vnc_malloc_fb;
+    client->GotFrameBufferUpdate=vnc_update;
+    if(!rfbInitClient(client,&argc,argv)) {
+        printf("usage: %s [-o output_file] [-t seconds-per-file] [-f frames-per-second] server:port\n", argv[0]);
+        return 1;
+    }
+
+    return( 0);
+}
+
+int is_fs_full()
+{
+    struct statvfs fs_usage;
+    statvfs( VIDEO_DIR_TMP, &fs_usage );
+//    printf("%f (%d,%d) bytes available\n", fs_usage.f_frsize*(double)fs_usage.f_bavail, fs_usage.f_frsize, fs_usage.f_bavail );
+    if( fs_usage.f_frsize*(double)fs_usage.f_bavail < MIN_SPACE_SIZE )
+    {
+        printf("%f (%d,%d) bytes available on filesystem %s - record stopped\n", fs_usage.f_frsize*(double)fs_usage.f_bavail, fs_usage.f_frsize, fs_usage.f_bavail, VIDEO_DIR_TMP );
+        return 1;
+    }
+    return 0;
+}
+
+/**************************************************************/
+/* media file output */
+int main(int argc, char **argv)
+{
+    int i,j;
+    int partnum = 1;
+
+    if( is_fs_full()) {
+       return( 1);
+    }
 
     /* Initialize libavcodec, and register all codecs and formats. */
 #if LIBAVUTIL_VERSION_MAJOR < 56 /* deprecrated in FFMPEG 4.0 */
@@ -432,6 +538,13 @@
 			max_time = 0;
 		    }
                     j+=2;
+            } else if(argc>i+1 && !strcmp("-f",argv[i])) {
+                    framerate=atoi(argv[i+1]);
+		    if (framerate < 1 || framerate > 30) {
+			fprintf(stderr, "Warning: Nonsensical frame-per-second %d, resetting to default.\n", framerate);
+			framerate = 10;
+		    }
+                    j+=2;
             }
             /* This is so that argc/argv are ready for passing to rfbInitClient */
             if(j>i) {
@@ -443,36 +556,286 @@
 
     /* default filename. */
     if (!filename) {
-        fprintf(stderr, "Warning: No filename specified. Using output.mp4\n");
-        filename = "output.mp4";
+//        fprintf(stderr, "Warning: No filename specified. Using output.mp4\n");
+//        filename = "output.mp4";
+        fprintf(stderr, "Warning: No filename specified. Using output.avi\n");
+        filename = VIDEO_DIR_TMP "output.avi";
     }
 
-    /* open VNC connection. */
-    client->MallocFrameBuffer=vnc_malloc_fb;
-    client->GotFrameBufferUpdate=vnc_update;
-    if(!rfbInitClient(client,&argc,argv)) {
-        printf("usage: %s [-o output_file] [-t seconds-per-file] server:port\n", argv[0]);
-        return 1;
+    mkdir(  VIDEO_DIR_TMP, 0755 );
+    mkdir(  VIDEO_DIR_RES, 0755 );
+
+#ifdef USE_SEP_AVFRAMES
+    if( init_client( argc, argv ))
+    {
+       return( 1);
     }
+#endif
 
+    while( !quit )
+    {
+    time_t full_time = time( NULL );
+    struct tm date_time_info;
+    localtime_r(&full_time, &date_time_info);
+    snprintf( full_fname, sizeof( full_fname ), "%svideo_%04d-%02d-%02d-%02d-%02d-%02d_part%d.avi",
+         VIDEO_DIR_RES,
+         date_time_info.tm_year+1900,    /* Year - 1900 */
+         date_time_info.tm_mon+1,        /* Month (0-11) */
+         date_time_info.tm_mday,         /* Day of the month (1-31) */
+         date_time_info.tm_hour,         /* Hours (0-23) */
+         date_time_info.tm_min,          /* Minutes (0-59) */
+         date_time_info.tm_sec,           /* Seconds (0-60) */
+         partnum++
+         );
+    printf( "%s started\n", full_fname );
+
+#ifndef USE_SEP_AVFRAMES
+    if( init_client( argc, argv ))
+    {
+       break;
+    }
+#endif
+
+    struct timeval tv;
+    gettimeofday( &tv, NULL );
     /* main loop */
     clock_gettime(CLOCK_MONOTONIC, &start_time);
     while(!quit) {
+//    gettimeofday( &tv, NULL );
+//printf( "1 %ld:%ld\n", tv.tv_sec, tv.tv_usec ); //fflush( stdout );
         int i=WaitForMessage(client,10000/framerate); /* useful for timeout to be no more than 10 msec per second (=10000/framerate usec) */
+//    gettimeofday( &tv, NULL );
+//printf( "2 %d %ld:%ld\n", i, tv.tv_sec, tv.tv_usec ); //fflush( stdout );
 	if (i>0) {
+//printf( "3\n" ); //fflush( stdout );
             if(!HandleRFBServerMessage(client))
                 quit=TRUE;
+//printf( "4\n" ); //fflush( stdout );
         } else if (i<0) {
             quit=TRUE;
 	}
         if (!quit) {
+//    gettimeofday( &tv, NULL );
+//printf( "5 %ld:%ld\n", tv.tv_sec, tv.tv_usec ); //fflush( stdout );
             clock_gettime(CLOCK_MONOTONIC, &cur_time);
             write_video_frame(oc, &video_st, time_to_pts(framerate, &start_time, &cur_time));
             if ((cur_time.tv_sec - start_time.tv_sec) > max_time && max_time > 0) {
-		quit = TRUE;
+		//quit = TRUE;
+                break;
             }
+//    gettimeofday( &tv, NULL );
+//printf( "6 %ld:%ld\n", tv.tv_sec, tv.tv_usec ); //fflush( stdout );
+            if( is_fs_full()) {
+                quit=TRUE;
+	    }
         }
     }
+
+//printf( "7\n" ); //fflush( stdout );
     movie_close(&oc,&video_st);
+    check_and_rename();
+#ifdef USE_SEP_AVFRAMES
+    if(!quit)
+    {
+        oc = movie_open(filename, &video_st, bitrate, framerate, client->width, client->height);
+	if (!oc) 
+	    break;
+    }
+#else
+    rfbClientCleanup(client);
+    client = NULL;
+    memset( &video_st, 0, sizeof( video_st ));
+    oc = NULL;
+#endif
+//printf( "8\n" ); //fflush( stdout );
+
+    printf( "%s finished\n", full_fname );
+    }
+
+#ifdef USE_SEP_AVFRAMES
+    if( frame ) av_frame_free(&frame);
+    if( tmp_frame ) av_frame_free(&tmp_frame);
+#endif
+
     return 0;
 }
+
+#endif
+
+
+#if 0
+#include <stdlib.h>
+#include <stdio.h>
+#include <string.h>
+#include <math.h>
+#include <signal.h>
+#include <sys/time.h>
+#include <libavcodec/avcodec.h>
+#include <libavformat/avformat.h>
+#include <libswscale/swscale.h>
+#include <rfb/rfbclient.h>
+
+#define DATASIZE (1024*1024)
+
+AVStream * add_vidio_stream (AVFormatContext * oc, enum AVCodecID codec_id) // используется для инициализации структуры AVFormatContext для вывода
+{
+  AVStream *st;
+  const AVCodec *codec;
+  AVCodecContext *enc;
+  int ret;
+
+  codec = avcodec_find_encoder (codec_id); // Находим декодер mjpeg
+  if (!codec)
+  {
+    printf("codec not found\n");
+    exit(1);
+  }
+
+#if 0
+  st = avformat_new_stream(oc, NULL);
+  if (!st)
+  {
+    printf("Could not alloc stream\n");
+    exit(1);
+  }
+
+  avcodec_get_context_defaults3(st->codec, codec); // Применяем для AVStream-> codec (объект AVCodecContext) пробел и устанавливаем значения по умолчанию (устанавливаются с помощью avcodec_get_context_defaults3 ()
+  st->codec->bit_rate = 400000; // Устанавливаем параметры выборки, а именно битрейт
+  st->codec->width = 1080; // Устанавливаем ширину и высоту видео, здесь они совпадают с шириной и высотой картинки.
+  st->codec->height = 1800;
+  st->codec->time_base.den = 10; // Устанавливаем частоту кадров
+  st->codec->time_base.num = 1;
+
+  st->codec->pix_fmt = PIX_FMT_YUV420P; // Устанавливаем формат пикселей
+  st->codec->codec_tag = 0;
+
+  if (oc->oformat->flags & AVFMT_GLOBALHEADER) // Некоторые форматы требуют отдельных заголовков данных видеопотока
+  {
+    st->codec->flags |= CODEC_FLAG_GLOBAL_HEADER;
+  }
+
+#else
+  enc = avcodec_alloc_context3( codec );
+  enc->codec_id = codec_id;
+
+  enc->bit_rate = 400000; // Устанавливаем параметры выборки, а именно битрейт
+  enc->width = 1080; // Устанавливаем ширину и высоту видео, здесь они совпадают с шириной и высотой картинки.
+  enc->height = 1800;
+  enc->time_base.den = 10; // Устанавливаем частоту кадров
+  enc->time_base.num = 1;
+
+  enc->pix_fmt = AV_PIX_FMT_YUVJ420P; // Устанавливаем формат пикселей
+  enc->codec_tag = 0;
+
+  st = avformat_new_stream( oc, codec );
+  if (!st) {
+      fprintf(stderr, "Could not allocate stream\n");
+      avcodec_free_context(&enc);
+      return NULL;
+  } // stream memory cleared up when oc is freed, so no need to do so later in this function on error
+  st->id = oc->nb_streams-1;
+  st->time_base = enc->time_base;
+
+  if (oc->oformat->flags & AVFMT_GLOBALHEADER)
+      enc->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;
+
+  ret = avcodec_open2(enc, codec, NULL);
+  if (ret < 0) {
+      fprintf(stderr, "Could not open video codec: %s\n", av_err2str(ret));
+        return NULL;
+  } // memory from this call freed when oc is freed, no need to do it on error in this call
+  /* copy the stream parameters to the muxer */
+  ret = avcodec_parameters_from_context(st->codecpar, enc);
+  if (ret < 0) {
+      fprintf(stderr, "Could not copy the stream parameters.\n");
+      return NULL;
+  } // memory from this call is freed when oc (parent of ost->st) is freed, no need to do it on error in this call
+
+#endif
+
+  return st;
+}
+
+void main()
+{
+  AVFormatContext * ofmt_ctx = NULL; // Он содержит множество параметров кодового потока, это структура данных, которая проходит через нее, и многие функции используют ее как параметр
+  const char * out_filename = "output.avi"; // путь к выходному файлу, здесь вы также можете изменить mkv на другие форматы, поддерживаемые ffmpeg, такие как mp4, flv, avi и т.п.
+  int ret; // знак возврата
+
+//  av_register_all (); // Инициализируем декодер и мультиплексор
+
+  avformat_alloc_output_context2 (& ofmt_ctx, NULL, "avi", out_filename); // Инициализируем структуру AVFormatContext для вывода, частота кадров, ширина и высота видео устанавливаются в этой функции
+  if (!ofmt_ctx)
+  {
+    printf("Could not create output context\n");
+    return;
+  }
+
+  AVStream * out_stream = add_vidio_stream (ofmt_ctx, AV_CODEC_ID_MJPEG); // Создаем выходной видеопоток
+//  AVStream * out_stream = add_vidio_stream (ofmt_ctx, ofmt_ctx->oformat->video_codec); // Создаем выходной видеопоток
+  if( !out_stream )
+  {
+    printf("Could not create video stream\n");
+    return;
+  }
+
+printf( "av_dump_format start\n" );
+  av_dump_format (ofmt_ctx, 0, out_filename, 1); // Эта функция распечатает информацию о видеопотоке, если вы выглядите недовольным, не
+printf( "av_dump_format stop\n" );
+
+  if (! (ofmt_ctx-> oformat-> flags & AVFMT_NOFILE)) // Открываем выходной видеофайл
+  {
+printf( "avio_open start\n" );
+    ret = avio_open(&ofmt_ctx->pb, out_filename, AVIO_FLAG_WRITE);
+printf( "avio_open stop ret=%d\n", ret );
+    if (ret < 0) {
+      printf("Could not open output file '%s'", out_filename);
+      return;
+    }
+  }
+
+  if (avformat_write_header (ofmt_ctx, NULL) <0) // Записываем заголовок файла
+  {
+    printf("Error occurred when opening output file\n");
+    return;
+  }
+
+  int frame_index = 0; // Количество изображений, вставленных в видео
+  unsigned char *mydata = malloc( DATASIZE ); //new unsigned char[DATASIZE];
+  AVPacket pkt = { 0 };
+//  av_init_packet(&pkt);
+  pkt.flags |= AV_PKT_FLAG_KEY;
+  pkt.stream_index = out_stream->index; // Получаем видео информацию, готовимся к нажатию на изображение кадра
+
+  while (frame_index <100) // Вставляем изображение в видео
+  {
+    FILE * file; // Открываем изображение в формате jpeg и считываем его данные, где максимальный размер изображения составляет 1M, если он превышает 1M, вам нужно изменить здесь 1024 * 1024
+    file = fopen("1.jpg", "rb");
+    if( !file ) break;
+    pkt.size = fread(mydata, 1, DATASIZE, file);
+    pkt.data = mydata;
+    fclose(file);
+
+    if (av_interleaved_write_frame (ofmt_ctx, & pkt) <0) // записываем изображение в видео
+    {
+      printf("Error muxing packet\n");
+      break;
+    }
+
+    printf ("Recorded %8d\n", frame_index); // Распечатать количество нажатых в данный момент кадров
+    frame_index++;
+  }
+
+//  av_free_packet (& pkt); // Освободить объект пакета отброшенного кадра
+  av_write_trailer (ofmt_ctx); // Записываем трейлер файла
+
+  free( mydata ); // Освободить объект данных
+
+  if (ofmt_ctx && !(ofmt_ctx->oformat->flags & AVFMT_NOFILE))
+    avio_close (ofmt_ctx-> pb); // Закрываем видео файл
+
+  avformat_free_context (ofmt_ctx); // Освободить структуру данных, относящуюся к выходному видео
+}
+
+#endif
+
diff -r -u --new-file a/CMakeLists.txt b/CMakeLists.txt
--- a/CMakeLists.txt	2022-10-19 16:40:54.531955674 +0300
+++ b/CMakeLists.txt	2022-10-21 00:19:16.749252355 +0300
@@ -152,7 +152,7 @@
 endif(WITH_GCRYPT)
 
 if(WITH_FFMPEG)
-  find_package(FFMPEG 3.1.0 COMPONENTS avformat avcodec avutil swscale)
+  find_package(FFMPEG 3.1.0 COMPONENTS avformat avcodec avutil swscale swresample avfilter)
 endif(WITH_FFMPEG)
 
 
@@ -596,6 +596,10 @@
     ${LIBVNCCLIENT_EXAMPLES}
     vnc2mpg
   )
+  set(FFMPEG_LIBRARIES
+    ${FFMPEG_LIBRARIES}
+    -lm
+  )
 endif(FFMPEG_FOUND)
 
 
@@ -720,6 +724,7 @@
 if(LIBVNCSERVER_INSTALL)
   install(TARGETS vncserver DESTINATION ${CMAKE_INSTALL_LIBDIR})
   install(TARGETS vncclient DESTINATION ${CMAKE_INSTALL_LIBDIR})
+  install(TARGETS client_examples_vnc2mpg DESTINATION ${CMAKE_INSTALL_BINDIR})
   install(FILES
     rfb/keysym.h
     rfb/threading.h
diff -r -u --new-file a/libvncclient/rfbproto.c b/libvncclient/rfbproto.c
--- a/libvncclient/rfbproto.c	2022-10-19 16:40:54.543955584 +0300
+++ b/libvncclient/rfbproto.c	2022-10-21 00:19:16.753252320 +0300
@@ -65,6 +65,8 @@
 #endif
 #include "tls.h"
 
+#define printf(...)
+
 #define MAX_TEXTCHAT_SIZE 10485760 /* 10MB */
 
 /*
@@ -1619,7 +1621,7 @@
     client->vncRec->readTimestamp = TRUE;
   if (!ReadFromRFBServer(client, (char *)&msg, 1))
     return FALSE;
-
+printf( "HandleRFBServerMessage %d\n", msg.type );
   switch (msg.type) {
 
   case rfbSetColourMapEntries:
@@ -1657,19 +1659,22 @@
     int linesToRead;
     int bytesPerLine;
     int i;
-
+printf( "77_1\n" );
     if (!ReadFromRFBServer(client, ((char *)&msg.fu) + 1,
 			   sz_rfbFramebufferUpdateMsg - 1))
       return FALSE;
 
     msg.fu.nRects = rfbClientSwap16IfLE(msg.fu.nRects);
 
+printf( "77_1_1 %d\n", msg.fu.nRects );
     for (i = 0; i < msg.fu.nRects; i++) {
       if (!ReadFromRFBServer(client, (char *)&rect, sz_rfbFramebufferUpdateRectHeader))
 	return FALSE;
 
+printf( "77_2 %x %d\n", rect.encoding, *(char *)&client->endianTest );
       rect.encoding = rfbClientSwap32IfLE(rect.encoding);
-      if (rect.encoding == rfbEncodingLastRect)
+printf( "77_2_1 %x %d\n", rect.encoding, *(char *)&client->endianTest );
+      if (rect.encoding == rfbEncodingLastRect )//|| rect.encoding == 0x20ffffff)
 	break;
 
       rect.r.x = rfbClientSwap16IfLE(rect.r.x);
@@ -1696,6 +1701,7 @@
 	continue;
       }
       
+printf( "77_3\n" );
       if (rect.encoding == rfbEncodingKeyboardLedState) {
           /* OK! We have received a keyboard state message!!! */
           client->KeyboardLedStateEnabled = 1;
@@ -1719,6 +1725,7 @@
 	continue;
       }
 
+printf( "77_4\n" );
       /* rect.r.w=byte count */
       if (rect.encoding == rfbEncodingSupportedMessages) {
           int loop;
@@ -1746,6 +1753,7 @@
           continue;
       }
 
+printf( "77_5\n" );
       /* rect.r.w=byte count, rect.r.h=# of encodings */
       if (rect.encoding == rfbEncodingSupportedEncodings) {
           char *buffer;
@@ -1777,6 +1785,7 @@
           continue;
       }
 
+printf( "77_6\n" );
       /* rfbEncodingUltraZip is a collection of subrects.   x = # of subrects, and h is always 0 */
       if (rect.encoding != rfbEncodingUltraZip)
       {
@@ -1803,6 +1812,7 @@
         client->SoftCursorLockArea(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h);
       }
 
+printf( "77_7 %d\n", *(char *)&client->endianTest );
       switch (rect.encoding) {
 
       case rfbEncodingRaw: {
@@ -2011,18 +2021,23 @@
 #ifdef LIBVNCSERVER_HAVE_LIBJPEG
       case rfbEncodingTight:
       {
+printf( "77_7_7 %d %d\n", client->format.bitsPerPixel, *(char *)&client->endianTest );
 	switch (client->format.bitsPerPixel) {
 	case 8:
 	  if (!HandleTight8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))
 	    return FALSE;
 	  break;
 	case 16:
+printf( "77_7_7_16 %d %d %d %d start\n", rect.r.x,rect.r.y,rect.r.w,rect.r.h );
 	  if (!HandleTight16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))
 	    return FALSE;
+printf( "77_7_7_16 %d %d %d %d done\n", rect.r.x,rect.r.y,rect.r.w,rect.r.h );
 	  break;
 	case 32:
+printf( "77_7_7_32 %d %d %d %d start %d\n", rect.r.x,rect.r.y,rect.r.w,rect.r.h, *(char *)&client->endianTest );
 	  if (!HandleTight32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))
 	    return FALSE;
+printf( "77_7_7_32 %d %d %d %d done %d\n", rect.r.x,rect.r.y,rect.r.w,rect.r.h, *(char *)&client->endianTest );
 	  break;
 	}
 	break;
@@ -2090,6 +2105,7 @@
 	 }
       }
 
+printf( "77_8\n" );
       /* Now we may discard "soft cursor locks". */
       client->SoftCursorUnlockScreen(client);
 
@@ -2099,9 +2115,11 @@
     if (!SendIncrementalFramebufferUpdateRequest(client))
       return FALSE;
 
+printf( "77_9\n" );
     if (client->FinishedFrameBufferUpdate)
       client->FinishedFrameBufferUpdate(client);
 
+printf( "77_10\n" );
     break;
   }
 
diff -r -u --new-file a/libvncclient/tight.c b/libvncclient/tight.c
--- a/libvncclient/tight.c	2022-10-19 16:40:54.543955584 +0300
+++ b/libvncclient/tight.c	2022-10-21 00:19:16.753252320 +0300
@@ -25,6 +25,8 @@
 
 #include "turbojpeg.h"
 
+#define printf(...)
+
 /*
  * tight.c - handle ``tight'' encoding.
  *
@@ -104,7 +106,7 @@
   int err, stream_id, compressedLen, bitsPixel;
   int bufferSize, rowSize, numRows, portionLen, rowsProcessed, extraBytes;
   rfbBool readUncompressed = FALSE;
-
+printf( "77_7_7_16_1 %d\n", *(char *)&client->endianTest);
   if (client->frameBuffer == NULL)
     return FALSE;
 
@@ -113,6 +115,7 @@
     return FALSE;
   }
 
+printf( "77_7_7_16_2 %d\n", *(char *)&client->endianTest);
   if (!ReadFromRFBServer(client, (char *)&comp_ctl, 1))
     return FALSE;
 
@@ -127,6 +130,7 @@
     comp_ctl >>= 1;
   }
 
+printf( "77_7_7_16_3 %d\n", *(char *)&client->endianTest);
   if ((comp_ctl & rfbTightNoZlib) == rfbTightNoZlib) {
      comp_ctl &= ~(rfbTightNoZlib);
      readUncompressed = TRUE;
@@ -135,25 +139,33 @@
   /* Handle solid rectangles. */
   if (comp_ctl == rfbTightFill) {
 #if BPP == 32
+printf( "77_7_7_16_3_1 %d\n", *(char *)&client->endianTest);
     if (client->format.depth == 24 && client->format.redMax == 0xFF &&
 	client->format.greenMax == 0xFF && client->format.blueMax == 0xFF) {
+printf( "77_7_7_16_3_2 %d\n", *(char *)&client->endianTest);
       if (!ReadFromRFBServer(client, client->buffer, 3))
 	return FALSE;
+printf( "77_7_7_16_3_3 %d\n", *(char *)&client->endianTest);
       fill_colour = RGB24_TO_PIXEL32(client->buffer[0], client->buffer[1], client->buffer[2]);
     } else {
+printf( "77_7_7_16_3_4 %d\n", *(char *)&client->endianTest);
       if (!ReadFromRFBServer(client, (char*)&fill_colour, sizeof(fill_colour)))
 	return FALSE;
+printf( "77_7_7_16_3_5 %d\n", *(char *)&client->endianTest);
     }
 #else
     if (!ReadFromRFBServer(client, (char*)&fill_colour, sizeof(fill_colour)))
 	return FALSE;
 #endif
 
+printf( "77_7_7_16_3_6 %d\n", *(char *)&client->endianTest);
     client->GotFillRect(client, rx, ry, rw, rh, fill_colour);
+printf( "77_7_7_16_3_7 %d\n", *(char *)&client->endianTest);
 
     return TRUE;
   }
 
+printf( "77_7_7_16_4 %d\n", *(char *)&client->endianTest);
 #if BPP == 8
   if (comp_ctl == rfbTightJpeg) {
     rfbClientLog("Tight encoding: JPEG is not supported in 8 bpp mode.\n");
@@ -161,6 +173,7 @@
   }
 #else
   if (comp_ctl == rfbTightJpeg) {
+printf( "77_7_7_16_4_1 %d\n", *(char *)&client->endianTest);
     return DecompressJpegRectBPP(client, rx, ry, rw, rh);
   }
 #endif
@@ -176,6 +189,7 @@
    * Data was processed with optional filter + zlib compression.
    */
 
+printf( "77_7_7_16_5 %d\n", *(char *)&client->endianTest);
   /* First, we should identify a filter to use. */
   if ((comp_ctl & rfbTightExplicitFilter) != 0) {
     if (!ReadFromRFBServer(client, (char*)&filter_id, 1))
@@ -207,6 +221,7 @@
     return FALSE;
   }
 
+printf( "77_7_7_16_6 %d\n", *(char *)&client->endianTest);
   /* Determine if the data should be decompressed or just copied. */
   rowSize = (rw * bitsPixel + 7) / 8;
   if (rh * rowSize < TIGHT_MIN_TO_COMPRESS) {
@@ -218,6 +233,7 @@
     return TRUE;
   }
 
+printf( "77_7_7_16_7 %d\n", *(char *)&client->endianTest);
   /* Read the length (1..3 bytes) of compressed data following. */
   compressedLen = (int)ReadCompactLen(client);
   if (compressedLen <= 0) {
@@ -233,6 +249,7 @@
     return TRUE;
   }
 
+printf( "77_7_7_16_8 %d\n", *(char *)&client->endianTest);
   /* Now let's initialize compression stream if needed. */
   stream_id = comp_ctl & 0x03;
   zs = &client->zlibStream[stream_id];
@@ -258,6 +275,7 @@
     return FALSE;
   }
 
+printf( "77_7_7_16_9 %d\n", *(char *)&client->endianTest);
   rowsProcessed = 0;
   extraBytes = 0;
 
@@ -304,11 +322,13 @@
     while (zs->avail_out == 0);
   }
 
+printf( "77_7_7_16_10 %d\n", *(char *)&client->endianTest);
   if (rowsProcessed != rh) {
     rfbClientLog("Incorrect number of scan lines after decompression.\n");
     return FALSE;
   }
 
+printf( "77_7_7_16_11 %d\n", *(char *)&client->endianTest);
   return TRUE;
 }
 
@@ -557,27 +577,31 @@
   int compressedLen;
   uint8_t *compressedData, *dst;
   int pixelSize, pitch, flags = 0;
-
+printf( "77_7_7_16_4_1_1 %d\n", *(char *)&client->endianTest);
   compressedLen = (int)ReadCompactLen(client);
   if (compressedLen <= 0) {
     rfbClientLog("Incorrect data received from the server.\n");
     return FALSE;
   }
 
+printf( "77_7_7_16_4_1_2 %d %d\n", compressedLen, *(char *)&client->endianTest);
   compressedData = malloc(compressedLen);
   if (compressedData == NULL) {
     rfbClientLog("Memory allocation error.\n");
     return FALSE;
   }
 
+printf( "77_7_7_16_4_1_3 %d\n", *(char *)&client->endianTest);
   if (!ReadFromRFBServer(client, (char*)compressedData, compressedLen)) {
     free(compressedData);
     return FALSE;
   }
 
+printf( "77_7_7_16_4_1_4 %d\n", *(char *)&client->endianTest);
   if(client->GotJpeg != NULL)
     return client->GotJpeg(client, compressedData, compressedLen, x, y, w, h);
   
+printf( "77_7_7_16_4_1_5 %d\n", *(char *)&client->endianTest);
   if (!client->tjhnd) {
     if ((client->tjhnd = tjInitDecompress()) == NULL) {
       rfbClientLog("TurboJPEG error: %s\n", tjGetErrorStr());
@@ -586,6 +610,7 @@
     }
   }
 
+printf( "77_7_7_16_4_1_6 %d\n", *(char *)&client->endianTest);
 #if BPP == 16
   flags = 0;
   pixelSize = 3;
@@ -601,6 +626,7 @@
   dst = &client->frameBuffer[y * pitch + x * pixelSize];
 #endif
 
+printf( "77_7_7_16_4_1_7 %d\n", *(char *)&client->endianTest);
   if (tjDecompress(client->tjhnd, compressedData, (unsigned long)compressedLen,
                    dst, w, pitch, h, pixelSize, flags)==-1) {
     rfbClientLog("TurboJPEG error: %s\n", tjGetErrorStr());
@@ -608,6 +634,7 @@
     return FALSE;
   }
 
+printf( "77_7_7_16_4_1_8 %d\n", *(char *)&client->endianTest);
   free(compressedData);
 
 #if BPP == 16
@@ -628,6 +655,7 @@
   }
 #endif
 
+printf( "77_7_7_16_4_1_9 %d\n", *(char *)&client->endianTest);
   return TRUE;
 }
 
diff -r -u --new-file a/libvncclient/vncviewer.c b/libvncclient/vncviewer.c
--- a/libvncclient/vncviewer.c	2022-10-19 16:40:54.543955584 +0300
+++ b/libvncclient/vncviewer.c	2022-10-21 00:19:16.753252320 +0300
@@ -52,6 +52,8 @@
 #include <termios.h>
 #endif
 
+#define printf(...)
+
 static char* ReadPassword(rfbClient* client) {
 	int i;
 	char* p=calloc(1,9);
@@ -90,6 +92,7 @@
      'width' and 'height' are 16-bit integers per RFB protocol design
      SIZE_MAX is the maximum value that can fit into size_t
   */
+printf( "frameBuffer %d %d %d\n", client->width, client->height, client->format.bitsPerPixel );
   allocSize = (uint64_t)client->width * client->height * client->format.bitsPerPixel/8;
 
   if (allocSize >= SIZE_MAX) {
